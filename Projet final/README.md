# Projet Final â€“ Pipeline Big Data PySpark

## Objectif  
Assembler les 4 briques de votre formation Â« Big Data avec PySpark Â» en un **pipeline complet** :  
1. ETL local (Lab 1)  
2. Pipeline batch distribuÃ© (Lab 2)  
3. Optimisation / fiabilitÃ© (Lab 3)  
4. Streaming en temps rÃ©el (Lab 4)  

Le dataset utilisÃ© est le dataset industriel Â« Industrial Equipment Monitoring Â» (ou un Ã©quivalent), reprÃ©sentant des logs de capteurs dâ€™Ã©quipements industriels.  

## Dataset  
- Source : [Industrial Equipment Monitoring Dataset](https://www.kaggle.com/datasets/dnkumars/industrial-equipment-monitoring-dataset) :contentReference[oaicite:6]{index=6}  
- Contenu typique : timestamp, equipment_id, sensor_id, vibration, temperature, pressure, status_code, etc.  
- Exemple de lignes :  
2025-10-11T08:00:00Z,EQ01,S1234,62.4,101.2,OK
2025-10-11T08:00:01Z,EQ01,S1234,62.8,100.8,OK

---

## Parcours pÃ©dagogique  
### Lab 1 â€“ ETL local  
- Charger `industrial_monitoring_logs.csv` avec PySpark en mode local.  
- Nettoyer les donnÃ©es (valeurs manquantes, status_code, etc.).  
- Ajouter une colonne `health_category` (ex : Â« normal Â», Â« warning Â», Â« critical Â») selon les capteurs/vibrations.  
- AgrÃ©ger par Ã©quipement et catÃ©gorie de santÃ©, sauvegarder en Parquet.

### Lab 2 â€“ Pipeline batch distribuÃ©  
- Lire le mÃªme dataset mais en partitionnant/logs volumineux.  
- Extraire des mÃ©triques par heure et par Ã©quipement.  
- Joindre avec un fichier enrichissement Ã©ventuel (ex : equipment_metadata.csv).  
- Sauvegarder partitionnÃ© (par date ou Ã©quipement) en Parquet.

### Lab 3 â€“ Optimisation & fiabilitÃ©  
- Analyser le plan dâ€™exÃ©cution (`.explain()`, Spark UI).  
- Ajuster `repartition`, utiliser `broadcast join`, `cache`, etc.  
- Mettre en place un checkpoint ou gestion fail-safe.  
- Documenter avant/aprÃ¨s performances.

### Lab 4 â€“ Streaming en temps rÃ©el  
- Simuler un flux capteurs (socket ou Kafka) avec les donnÃ©es.  
- Lire en streaming avec PySpark Structured Streaming.  
- Appliquer une fenÃªtre temporelle (ex : 5 min glissantes) pour calculer la moyenne de vibration/tempÃ©rature par Ã©quipement.  
- Ã‰crire les rÃ©sultats en temps rÃ©el vers Parquet ou console.  
- Bonus : dÃ©tecter et alerter Â« critical Â» health_category.

## Livrables attendus  
- Scripts Python/notebooks pour chaque lab (`etl_local.py`, `pipeline_batch.py`, `optimize.py`, `streaming_iot.py`).  
- Dossier `output/` avec fichiers Parquet gÃ©nÃ©rÃ©s.  
- Documentation et captures dâ€™Ã©cran des performances (Lab 3).  
- README.md pour chaque lab (dÃ©jÃ  prÃ©parÃ©s).  

## Conseils pratiques  
- Commencez avec un sous-Ã©chantillon du dataset (ex. 1 M lignes) puis montez Ã  5-10 M pour ressentir lâ€™effet Big Data.  
- Utilisez lâ€™option `spark.sql.shuffle.partitions` pour tester lâ€™impact.  
- Pour le streaming, assurez-vous dâ€™utiliser une fenÃªtre raisonnable (ex. 1â€“5 minutes) afin que les rÃ©sultats soient observables pendant lâ€™exercice.

## Conclusion  
Ã€ la fin de ces 4 labs, vous disposerez dâ€™un **pipeline de donnÃ©es distribuÃ© complet**, passant du batch au streaming, avec optimisation et architecture fonctionnelle, prÃªt Ã  Ãªtre dÃ©ployÃ© ou prolongÃ© (ex : vers lâ€™IoT, le ML, la maintenance prÃ©dictive).  

Bon courage et amusez-vous bien ! ğŸ“  
