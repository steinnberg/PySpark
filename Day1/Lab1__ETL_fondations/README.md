## ğŸ§± LAB 1 â€” Fondations du traitement distribuÃ© (PySpark ETL local)

### ğŸ“ lab1_etl_fondations/README.md

---

### ğŸ¯ Objectifs pÃ©dagogiques

* Comprendre le fonctionnement de Spark et PySpark.
* Manipuler des DataFrames distribuÃ©s.
* RÃ©aliser un premier pipeline ETL local.

---

### ğŸ“š Concepts abordÃ©s

- **SparkSession** , **SparkContext**
- DataFrame, transformations (select, filter, groupBy, agg)
- Lazy evaluation et plan logique
- Sauvegarde de donnÃ©es (CSV, Parquet)

---

### ğŸ§© Ã‰tapes
- 1ï¸âƒ£ Initialiser PySpark

```python
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("ETL-local").getOrCreate()
```

- 2ï¸âƒ£ Charger un dataset local
* Ex. : data/users.csv

```python
df = spark.read.csv("../data/users.csv", header=True, inferSchema=True)
df.show(5)
```

- 3ï¸âƒ£ Nettoyer les donnÃ©es
```python
df_clean = df.filter(df.age.isNotNull()).filter(df.country != "Unknown")
```

- 4ï¸âƒ£ Transformer et agrÃ©ger
```python
df_country = df_clean.groupBy("country").agg({"age": "avg", "salary": "avg"})
df_country.show()
```

- 5ï¸âƒ£ Sauvegarder en Parquet
```python
df_country.write.mode("overwrite").parquet("../data/output/country_stats.parquet")
```

---

### ğŸ§  Ã€ faire assignements

1. Ajouter une colonne â€œage_categoryâ€ (jeune/adulte/senior).
2. Calculer le revenu moyen par catÃ©gorie et pays.
3. Visualiser le rÃ©sultat sous Pandas.

---

### âœ… Livrable

* Script : etl_local.py
* Fichier : output/country_stats.parquet