# LAB 3 â€” Optimisation et fiabilitÃ© du cluster

## ğŸ“ lab3_optimisation_spark/README.md

### ğŸ¯ Objectifs pÃ©dagogiques

- Optimiser les performances du pipeline Spark.
- Utiliser les fonctions de cache, broadcast et repartition.
- Comprendre le plan dâ€™exÃ©cution et le monitoring.

---

### ğŸ“š Concepts abordÃ©s

* Spark UI, plan dâ€™exÃ©cution
* Repartition, coalesce
* Broadcast join
* Cache et persist

---

### ğŸ§© Ã‰tapes
- 1ï¸âƒ£ Charger le pipeline du Lab 2
```python
df_logs = spark.read.parquet("../data/output/logs_hourly/")
```

- 2ï¸âƒ£ Ã‰tudier le plan
```python
df_logs.explain(True)
```

- 3ï¸âƒ£ Optimiser le partitionnement
```python
df_opt = df_logs.repartition(8)
df_opt.cache()
```

- 4ï¸âƒ£ Jointure optimisÃ©e
```python
from pyspark.sql.functions import broadcast
df_users = spark.read.csv("../data/users.csv", header=True, inferSchema=True)
df_joined = df_opt.join(broadcast(df_users), df_opt.user_id == df_users.id)
```

---

### ğŸ§  Ã€ faire : assaignement

1. Tester plusieurs niveaux de partitionnement (2, 4, 8).

2. Observer les temps dâ€™exÃ©cution.

3. Ajouter un checkpoint pour tolÃ©rance aux pannes.
---

### âœ… Livrable

* Rapport Markdown : optimisation_notes.md

* Graphiques Spark UI (capture dâ€™Ã©cran des stages)